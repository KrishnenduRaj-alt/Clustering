# -*- coding: utf-8 -*-
"""KMeansSynthetic.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nlOnKKaHmWdtQs6ZwTnyPMissBcnTkJ9
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

def get_dataset_size(file_path="dataset"):
    """
    Gives us the number of data points from the dataset by reading the provided file.

    Args include the path to the dataset file (default is 'dataset') [file_path (str)].

    Returns the number of data points in the dataset (int).
    """
    try:
        df = pd.read_csv(file_path, header=None, delim_whitespace=True)
        return len(df)
    except Exception as e:
        print(f"Error loading dataset: {e}")
        return 100  # Default value if dataset can't be loaded

def generate_synthetic_data(num_samples, num_features=2):
    """
    Gives us the synthetic data with the specified number of samples and features.

    Args include:
        1. The number of samples to generate [num_samples (int)].
        2. The number of features (default is 2)[num_features (int)].

    Returns a 2D numpy array containing the generated synthetic data [np.ndarray].
    """
    np.random.seed(42)
    return np.random.rand(num_samples, num_features)

def compute_distance(point1, point2):
    """
    .
    """
    return np.linalg.norm(point1 - point2)

def initial_selection(data, k):
    """
    Randomly select k initial cluster centers.
    """
    np.random.seed(42)
    return data[np.random.choice(len(data), k, replace=False)]

def assign_cluster_ids(data, centers):
    """
    Assign each data point to the nearest cluster center.
    """
    return np.array([np.argmin([compute_distance(point, center) for center in centers]) for point in data])

def compute_cluster_representatives(data, cluster_ids, k):
    """
    Compute new cluster centers as the mean of assigned points.
    If a cluster is empty, reinitialize it to a random data point.
    """
    new_centers = np.zeros((k, data.shape[1]))
    cluster_ids = np.array(cluster_ids)
    for i in range(k):
        cluster_points = data[cluster_ids == i]
        if cluster_points.shape[0] > 0:
            new_centers[i] = np.mean(cluster_points, axis=0)
        else:
            new_centers[i] = data[np.random.choice(len(data))]
    return new_centers

def kmeans_clustering(data, k, max_iters=100, tol=1e-4):
    """
    Perform K-Means clustering.
    Returns: Final cluster centers and cluster assignments.
    """
    centers = initial_selection(data, k)
    for _ in range(max_iters):
        cluster_ids = assign_cluster_ids(data, centers)
        new_centers = compute_cluster_representatives(data, cluster_ids, k)
        if np.linalg.norm(new_centers - centers) < tol:
            break
        centers = new_centers
    return centers, cluster_ids

def compute_silhouette_coefficient(data, cluster_ids, k):
    """
    Compute Silhouette coefficient for each cluster.
    """
    if k == 1 or len(np.unique(cluster_ids)) < 2:
        return 0  # Avoid invalid silhouette calculation

    silhouette_scores = []
    cluster_ids = np.array(cluster_ids)
    for i in range(len(data)):
        same_cluster = data[cluster_ids == cluster_ids[i]]
        other_clusters = [data[cluster_ids == j] for j in range(k) if j != cluster_ids[i] and data[cluster_ids == j].shape[0] > 0]

        if same_cluster.shape[0] > 1:
            a = np.mean([compute_distance(data[i], p) for p in same_cluster if not np.array_equal(p, data[i])])
        else:
            a = 0

        if other_clusters:
            b = np.min([np.mean([compute_distance(data[i], p) for p in cluster]) for cluster in other_clusters])
        else:
            b = 0

        silhouette_scores.append((b - a) / max(a, b) if max(a, b) > 0 else 0)

    return np.mean(silhouette_scores)

def plot_silhouette(synthetic_data):
    """
    Compute and plot Silhouette coefficient for k from 1 to 9 for synthetic data.
    """
    k_values = range(1, 10)
    synthetic_scores = []

    for k in k_values:
        _, synthetic_cluster_ids = kmeans_clustering(synthetic_data, k)
        synthetic_scores.append(compute_silhouette_coefficient(synthetic_data, synthetic_cluster_ids, k))

    plt.figure(figsize=(8, 5))
    plt.plot(k_values, synthetic_scores, marker='s', linestyle='--', label="Synthetic Data")
    plt.xlabel("Number of Clusters (k)")
    plt.ylabel("Silhouette Coefficient")
    plt.title("Silhouette Score vs. Number of Clusters")
    plt.legend()
    plt.grid()
    plt.savefig("silhouette_synthetic.png")
    plt.show()

if __name__ == "__main__":
    num_samples = get_dataset_size("dataset")
    synthetic_data = generate_synthetic_data(num_samples, 2)
    plot_silhouette(synthetic_data)